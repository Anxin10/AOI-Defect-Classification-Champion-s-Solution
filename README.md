
<div align="center">

# ğŸ¦… AOI Defect Classification: Champion's Solution
### å·¥æ¥­ç´šç‘•ç–µæª¢æ¸¬ç³»çµ± - å† è»è¨“ç·´æ–¹æ¡ˆ

[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg?style=for-the-badge)](LICENSE)
[![VRAM Optimization](https://img.shields.io/badge/VRAM-Optimized_for_24GB-success?style=for-the-badge)](config.py)
[![Status](https://img.shields.io/badge/Status-Production_Ready-success?style=for-the-badge)]()

**Combine Semi-Supervised Learning with High-Performance Ensemble**  
**å°ˆç‚º RTX 3090/4090 æ‰“é€ çš„ç¥ç´šè¨“ç·´æµç¨‹**

[Introduction](#-introduction-å°ˆæ¡ˆç°¡ä»‹) â€¢
[Methodology](#-methodology-æ ¸å¿ƒæŠ€è¡“) â€¢
[Installation](#-installation-å®‰è£æŒ‡å—) â€¢
[Pipeline](#-pipeline-åŸ·è¡Œæµç¨‹) â€¢
[Optimization](#-optimization-æ¥µé€Ÿå„ªåŒ–)

</div>

---

## ğŸ“– Introduction (å°ˆæ¡ˆç°¡ä»‹)

æœ¬å°ˆæ¡ˆå¯¦ç¾äº†ä¸€å€‹åŸºæ–¼ **Semi-Supervised Learning (åŠç›£ç£å­¸ç¿’)** çš„é«˜ç²¾åº¦ AOI ç‘•ç–µæª¢æ¸¬ç³»çµ±ã€‚æˆ‘å€‘çš„ç›®æ¨™æ˜¯åˆ©ç”¨ Pseudo Labeling (å½æ¨™ç±¤) æŠ€è¡“ï¼Œå°‡ 10,000 å¼µæœªæ¨™è¨»çš„æ¸¬è©¦é›†è³‡æ–™è½‰åŒ–ç‚ºè¨“ç·´è³‡æºï¼ŒæŒ‘æˆ° **99.9%** çš„åˆ†é¡æº–ç¢ºç‡ã€‚

é‡å°å·¥æ¥­ç´šæ‡‰ç”¨å ´æ™¯ï¼Œæˆ‘å€‘å¯¦ä½œäº†å¤šé … Kaggle Grandmaster ç­‰ç´šçš„æŠ€å·§ï¼Œè§£æ±ºäº† **é¡åˆ¥æ¥µåº¦ä¸å¹³è¡¡ (Class Imbalance)**ã€**é›™æµè¼¸å…¥çš„é¡¯å­˜ç“¶é ¸** ä»¥åŠ **æ¨¡å‹å´©æ½° (Mode Collapse)** ç­‰é—œéµç—›é»ã€‚

<div align="center">
  <img src="assets/overall_architecture.png" alt="Overall Architecture Diagram" width="95%">
</div>

---

---

## ğŸ† Strategic Solutions (æ ¸å¿ƒè§£é¡Œç­–ç•¥)

æˆ‘å€‘é‡å°å·¥æ¥­å ´æ™¯çš„ä¸‰å¤§ç—›é»ï¼Œæå‡ºäº†å…·é«”çš„æŠ€è¡“è§£æ±ºæ–¹æ¡ˆï¼š

### 1. ç ´è§£é¡åˆ¥æ¥µåº¦ä¸å¹³è¡¡ (Solving Class Imbalance) âš–ï¸

**ç—›é»**: "Horizontal Defect" (Label 2) åƒ…æœ‰ **100 å¼µ** (3.9%)ï¼Œè€Œ "Normal" æœ‰ 674 å¼µã€‚æ¨¡å‹æ¥µæ˜“å¿½ç•¥ç¨€æœ‰ç‘•ç–µï¼Œå°è‡´æ¼æª¢ (False Negative)ã€‚

**è§£æ±ºæ–¹æ¡ˆ**:
*   **Weighted Random Sampler (åŠ æ¬Šéš¨æ©Ÿæ¡æ¨£)**:
    *   æˆ‘å€‘ä¸ä½¿ç”¨æ¨™æº–æ¡æ¨£ï¼Œè€Œæ˜¯è³¦äºˆç¨€æœ‰é¡åˆ¥æ¥µé«˜çš„æ¬Šé‡ã€‚
    *   **æ©Ÿåˆ¶**: ç¢ºä¿åœ¨ä¸€å€‹ Epoch ä¸­ï¼Œæ¨¡å‹çœ‹åˆ° "Label 2" çš„æ¬¡æ•¸èˆ‡ "Label 0" ä¸€æ¨£å¤šã€‚é€™ç­‰åŒæ–¼å°ç¨€æœ‰ç‘•ç–µé€²è¡Œäº† **6.7å€** çš„éæ¡æ¨£ (Oversampling)ã€‚
*   **Threshold Optimization (é–¾å€¼å„ªåŒ–)**:
    *   å‚³çµ± Argmax (0.5) å°ç¨€æœ‰é¡åˆ¥ä¸åˆ©ã€‚æˆ‘å€‘åœ¨æ¨è«–éšæ®µå° Label 2 å¯¦æ–½ **Aggressive Recall** ç­–ç•¥ã€‚
    *   è‹¥ Label 2 çš„é æ¸¬æ©Ÿç‡ > **0.4** (è€Œé 0.5)ï¼Œå³å¼·åˆ¶åˆ¤å®šç‚ºç‘•ç–µï¼Œå¤§å¹…é™ä½æ¼æ®ºç‡ã€‚

### 2. çªç ´é¡¯å­˜ç“¶é ¸ (Overcoming VRAM Limits) ğŸ’¾

**ç—›é»**: å‚³çµ± "Dual Stream" (é›™æµ) ç¶²è·¯éœ€è¦åŒæ™‚è¼¸å…¥ "åŸåœ–" + "éŠ³åŒ–åœ–"ï¼Œé¡¯å­˜ä½”ç”¨ç¿»å€ (2x VRAM)ï¼Œå°è‡´ç„¡æ³•åœ¨ RTX 3090/4090 ä¸Šè¨“ç·´ Large æ¨¡å‹ã€‚

**è§£æ±ºæ–¹æ¡ˆ: Dual Stream Simulation (é›™æµæ™‚åŸŸæ¨¡æ“¬)**
æˆ‘å€‘åˆ©ç”¨ **æ™‚é–“è»¸ (Temporal Axis)** ä¾†æ¨¡æ“¬é›™æµã€‚ä¸å†åŒæ™‚è¼¸å…¥å…©å¼µåœ–ï¼Œè€Œæ˜¯åœ¨ `dataset.py` ä¸­è¨­ç½® **Augmentation Switch**ï¼š

<div align="center">
  <img src="assets/dual_stream_sim.png" alt="Dual Stream Simulation Diagram" width="85%">
</div>

*   **é‹ä½œåŸç†**:
    *   **Epoch N**: æ¨¡å‹æœ‰ 30% æ©Ÿç‡çœ‹åˆ° **æ¨¡ç³Š (Blur)** çš„å½±åƒ -> å¼·è¿«å­¸ç¿’ **å½¢ç‹€ (Shape)** ç‰¹å¾µã€‚
    *   **Epoch N+1**: æ¨¡å‹æœ‰ 30% æ©Ÿç‡çœ‹åˆ° **éŠ³åŒ– (Sharpen)** çš„å½±åƒ -> å¼·è¿«å­¸ç¿’ **ç´‹ç† (Texture)** ç‰¹å¾µã€‚
*   **æ•ˆç›Š**: å–®ä¸€æ¨¡å‹ (Single Stream) å»æ“æœ‰äº†é›™æµæ¨¡å‹çš„é­¯æ£’æ€§ï¼Œä¸” **VRAM é›¶å¢åŠ **ã€‚

### 3. é˜²æ­¢æ¨¡å‹å´©æ½° (Preventing Mode Collapse) ğŸ“‰

**ç—›é»**: Swin Transformer Large åœ¨è¨“ç·´åˆæœŸ (Warmup) æ¥µä¸ç©©å®šï¼Œæ¢¯åº¦å®¹æ˜“ç¬é–“çˆ†ç‚¸ (Gradient Explosion)ï¼Œå°è‡´ Loss å¡åœ¨ 1.79 (Mode Collapse)ï¼Œé æ¸¬å…¨è®Šç‚ºåŒä¸€é¡ã€‚

**è§£æ±ºæ–¹æ¡ˆ**:
*   **Gradient Clipping (æ¢¯åº¦å‰ªè£)**:
    *   åœ¨ Backpropagation ä¹‹å¾Œã€Optimizer Update ä¹‹å‰ï¼Œå¼·åˆ¶å°‡æ¢¯åº¦çš„ Norm é™åˆ¶åœ¨ **1.0** ä»¥å…§ã€‚
    *   `torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)`
    *   é€™å°±åƒ"ä¿éšªçµ²"ï¼Œç¢ºä¿å³ä½¿é‡åˆ°æ¥µç«¯æ•¸æ“šï¼Œæ¬Šé‡ä¹Ÿä¸æœƒè¢«ç‚¸é£›ã€‚
*   **3-Epoch Warmup**:
    *   å‰ 3 å€‹ Epoch å­¸ç¿’ç‡å¾ `1e-6` å¾ç·©å‡è‡³ `1e-4`ï¼Œè®“ Pretrained Weights èƒ½å¤ é©æ‡‰æ–°æ•¸æ“šçš„åˆ†ä½ˆã€‚

---

---

## âš™ï¸ Detailed Configuration Analysis (åƒæ•¸æ·±åº¦è§£æ)

ç‚ºäº†è®“æ‚¨å®Œå…¨æŒæ§è¨“ç·´ç´°ç¯€ï¼Œæˆ‘å€‘åœ¨æ­¤å…¬é–‹æ‰€æœ‰é—œéµåƒæ•¸çš„è¨­å®šé‚è¼¯èˆ‡æ•¸å€¼ã€‚æ‰€æœ‰è¨­å®šçš†ä½æ–¼ `config.py`ã€‚

### 1. Training Dynamics (è¨“ç·´å‹•æ…‹)

| åƒæ•¸ (Parameter) | æ•¸å€¼ (Value) | è¨­è¨ˆé‚è¼¯ (Rationale) |
| :--- | :--- | :--- |
| **`EPOCHS`** | 20 | æ ¹æ“šç¶“é©—ï¼ŒSwin/ConvNeXt åœ¨ 2,500 å¼µåœ–ä¸Šé€šå¸¸åœ¨ 15-20 Epochs æ”¶æ–‚ã€‚éå¤šå®¹æ˜“ Overfitã€‚ |
| **`WARMUP_EPOCHS`** | 3 | **é—œéµè¨­å®š**ã€‚å‰ 3 å€‹ Epochs å°‡ LR å¾ 1e-6 ç·šæ€§å‡è‡³ 1e-4ã€‚é€™æ˜¯ç‚ºäº†è®“åŸæœ¬åœ¨ ImageNet ä¸Šé è¨“ç·´å¥½çš„æ¬Šé‡ (Pretrained Weights) èƒ½å¤  "æº«å’Œåœ°" é©æ‡‰æ–°çš„å·¥æ¥­æ•¸æ“šï¼Œé¿å…ä¸€é–‹å§‹æ¢¯åº¦éå¤§ç ´å£ç‰¹å¾µæå–å±¤ã€‚ |
| **`LEARNING_RATE`** | 1e-4 | é…åˆ Cosine Annealing ç­–ç•¥ã€‚1e-4 æ˜¯ Transformer é¡æ¨¡å‹ Fine-tuning çš„é»ƒé‡‘èµ·é» (æ¯” CNN å¸¸ç”¨çš„ 1e-3 ä½ä¸€å€‹é‡ç´š)ã€‚ |
| **`EMA_DECAY`** | 0.995 | é‡å°å°æ•¸æ“šé›† (Small Data) çš„ç‰¹æ®Šèª¿æ•´ã€‚æ¨™æº– ImageNet è¨“ç·´é€šå¸¸ç”¨ 0.9999ï¼Œä½†åœ¨åªæœ‰ 2k å¼µåœ–çš„æƒ…æ³ä¸‹ï¼Œæ¬Šé‡æ›´æ–°å¤ªæ…¢æœƒå°è‡´ EMA è·Ÿä¸ä¸Šï¼Œå› æ­¤é™è‡³ 0.995 åŠ å¿«æ”¶æ–‚ã€‚ |
| **`WEIGHT_DECAY`** | 1e-2 | AdamW çš„æ¨™æº–æ¬Šé‡è¡°æ¸›ï¼Œé˜²æ­¢ Overfitã€‚ |
| **`MAX_NORM`** | 1.0 | **Gradient Clipping** é–¥å€¼ã€‚Swin Transformer å°æ¢¯åº¦éå¸¸æ•æ„Ÿï¼Œè¨­ç‚º 1.0 æ˜¯é˜²æ­¢è¨“ç·´ä¸­é€” Loss çªç„¶ç‚¸è£‚ (Spike) çš„ä¿éšªçµ²ã€‚ |

### 2. Augmentation Hyperparameters (å¢å¼·åƒæ•¸ç´°ç¯€)

æˆ‘å€‘åœ¨ `dataset.py` ä¸­å®šç¾©äº†æ¥µè‡´çš„å¢å¼·ç­–ç•¥ã€‚ä»¥ä¸‹æ˜¯ **Teacher Mode** çš„å…·é«”åƒæ•¸ï¼Œæ—¨åœ¨æ¨¡æ“¬çœŸå¯¦å·¥æ¥­å ´æ™¯è®Šç•°ï¼š

| å¢å¼·æ‰‹æ³• (Technique) | æ©Ÿç‡ (p) | å¼·åº¦/åƒæ•¸ (Magnitude) | ä½œç”¨ (Impact) |
| :--- | :--- | :--- | :--- |
| **Affine (ä»¿å°„è®Šæ›)** | 0.5 | Rotate Â±30Â°, Scale 0.85-1.15 | æ¨¡æ“¬è¼¸é€å¸¶ä¸Šå·¥ä»¶çš„æ­ªæ–œèˆ‡é è¿‘ç¸®æ”¾ã€‚ |
| **Dual Stream Sim** | 0.3 | Blur (Limit 3) vs Sharpen (Alpha 0.2-0.5) | **æ ¸å¿ƒæŠ€è¡“**ã€‚éš¨æ©Ÿæ¨¡æ“¬å¤±ç„¦ (Defocus) æˆ–éåº¦éŠ³åŒ– (Artifacts) çš„æˆåƒå“è³ªï¼Œå¼·è¿«æ¨¡å‹å­¸ç¿’é­¯æ£’ç‰¹å¾µã€‚ |
| **CoarseDropout** | 0.5 | Holes=8, Size=Image//10 | æ¨¡æ“¬å±€éƒ¨é®æ“‹æˆ–æ±¡æ¼¬ï¼Œè¿«ä½¿æ¨¡å‹çœ‹"æ•´é«”"è€Œé"å±€éƒ¨"ã€‚ |
| **HSV / Brightness** | 0.5 | Shift Limit 0.2 | æ¨¡æ“¬å…‰æºè®ŠåŒ–èˆ‡ä¸åŒæ©Ÿå°çš„è‰²å·®ã€‚ |

---

## ğŸ—ï¸ Model Architecture Decisions (æ¶æ§‹æ±ºç­–)

ç‚ºä»€éº¼é¸æ“‡é€™ä¸‰å£åŠï¼Ÿ

1.  **ConvNeXt V2 (Large)**:
    *   **è§’è‰²**: ä¸»åŠ›è¼¸å‡º (Anchor)ã€‚
    *   **ç†ç”±**: çµåˆäº† CNN çš„æ­¸ç´åç½® (Inductive Bias) èˆ‡ Transformer çš„è¨“ç·´ç­–ç•¥ã€‚å°æ–¼ "ç´‹ç†å‹" ç‘•ç–µ (å¦‚åˆ®ç—•) æª¢æ¸¬èƒ½åŠ›æœ€å¼·ã€‚
2.  **Swin Transformer V2 (Large)**:
    *   **è§’è‰²**: äº’è£œå°ˆå®¶ (Complementary Expert)ã€‚
    *   **ç†ç”±**: Window Attention æ©Ÿåˆ¶èƒ½æ•æ‰é•·è·é›¢ä¾è³´ã€‚å°æ–¼ "å¤§é¢ç©" æˆ– "çµæ§‹æ€§" ç‘•ç–µ (å¦‚å¤§å¡Šæ±¡æ¼¬) è¡¨ç¾å„ªæ–¼ CNNã€‚
3.  **EVA-02 (Large / MIM)**:
    *   **è§’è‰²**: ç©©å¥ç‰¹å¾µ (Robustness)ã€‚
    *   **ç†ç”±**: åŸºæ–¼ MIM (Masked Image Modeling) é è¨“ç·´ï¼Œå°æŠ—å™ªè²èˆ‡é®æ“‹çš„èƒ½åŠ›æ¥µå¼·ï¼Œèƒ½ä¿®æ­£åœ¨æ¥µç«¯å¢å¼·ä¸‹çš„èª¤åˆ¤ã€‚

---

## ğŸ›  Installation (å®‰è£æŒ‡å—)

### 1. ç’°å¢ƒè¨­å®š
å»ºè­°ä½¿ç”¨ Mamba/Conda å»ºç«‹ç’°å¢ƒï¼š
```bash
conda create -n aoi python=3.10
conda activate aoi
pip install -r requirements.txt
```

### 2. è³‡æ–™çµæ§‹
è«‹å°‡ `aoi_data.zip` è§£å£“è‡³å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„ `data/`ï¼š
```text
data/
â”œâ”€â”€ train_images/  (2,528 images)
â”œâ”€â”€ test_images/   (10,142 images)
â”œâ”€â”€ train.csv
â””â”€â”€ test.csv
```

---

## ğŸš€ Pipeline (åŸ·è¡Œæµç¨‹)

æ‚¨å¯ä»¥åŸ·è¡Œ `run_pipeline.sh` ä¸€éµå®Œæˆï¼Œæˆ–åƒè€ƒä»¥ä¸‹æ­¥é©Ÿæ‰‹å‹•åŸ·è¡Œã€‚

### Step 1: Teacher Model Training

é€™æ˜¯æ•´å€‹ Pipeline çš„åŸºçŸ³ã€‚æˆ‘å€‘ä½¿ç”¨ ImageNet Pretrained æ¨¡å‹é€²è¡Œé·ç§»å­¸ç¿’ã€‚

<div align="center">
  <img src="assets/teacher_flow.png" alt="Teacher Training Flow" width="60%">
</div>

```bash
# è¨“ç·´ Teacher æ¨¡å‹ (æ”¯æ´ convnext, swinv2, eva02)
python train_teacher.py --model convnext

# è¨“ç·´ Swin V2 (å¯é¸)
python train_teacher.py --model swinv2
```

### Step 2: Pseudo Labeling (ç”¢ç”Ÿå½æ¨™ç±¤)
```bash
# ç”¢ç”Ÿ train_pseudo.csv
python inference_pseudo.py
```
> **Note**: æ­¤æ­¥é©Ÿæœƒè‡ªå‹•è¼‰å…¥æ‰€æœ‰è¨“ç·´å¥½çš„æ¨¡å‹é€²è¡Œèˆ‡é›†æˆã€‚

### Step 3: Student Model Training

åˆ©ç”¨æ“´å¢å¾Œçš„æ•¸æ“šé›†é€²è¡Œ **Noisy Student Training**ã€‚

<div align="center">
  <img src="assets/student_flow.png" alt="Student Training Flow" width="60%">
</div>

```bash
# è¨“ç·´ Student æ¨¡å‹ (è®€å– train_pseudo.csv)
python train_student.py --model convnext
```

### Step 4: å† è»æ¨è«– (Multi-Model Champion Ensemble)

é€™æ˜¯æœ€çµ‚çš„é›†æˆè…³æœ¬ï¼Œæ”¯æ´ **å¤šæ¨¡å‹åŠ æ¬ŠæŠ•ç¥¨ (Weighted Voting)**ã€‚

<div align="center">
  <img src="assets/code_flow_diagram.png" alt="Inference Flow" width="70%">
</div>

```bash
python ensemble_inference.py --output submission.csv
```

#### ğŸ§ª Quick Check (å–®ä¸€æ¨¡å‹å¿«é€Ÿé©—è­‰)
å¦‚æœæ‚¨å‰›è¨“ç·´å¥½ä¸€å€‹æ¨¡å‹ (ä¾‹å¦‚ `convnext`) æƒ³é¦¬ä¸Šçœ‹çµæœï¼Œä¸éœ€è¦è·‘å®Œæ•´çš„é›†æˆï¼Œå¯ä»¥ä½¿ç”¨ `--model` åƒæ•¸ï¼š

```bash
# åƒ…ä½¿ç”¨ ConvNeXt é€²è¡Œæ¨è«–èˆ‡ Threshold Optimization
python ensemble_inference.py --model convnext --output submission_convnext.csv
```
> é€™æœƒè‡ªå‹•åŸ·è¡Œè©²æ¨¡å‹çš„ 5-Fold Ensembling + 5-View TTAï¼Œä¸¦ç”¢å‡ºé æ¸¬åˆ†ä½ˆä¾›æ‚¨æª¢æŸ¥ (ç‰¹åˆ¥æ³¨æ„ Label 2 çš„æ•¸é‡)ã€‚

**å¦‚ä½•èª¿å„ª**:
é–‹å•Ÿ `ensemble_inference.py`ï¼Œèª¿æ•´ `MODEL_WEIGHTS` å­—å…¸ï¼š
```python
MODEL_WEIGHTS = {
    'convnext': 0.50,  # ä¸»åŠ›æ¨¡å‹ (CVåˆ†æ•¸é«˜)
    'swinv2':   0.30,  # è¼”åŠ©æ¨¡å‹ (Transformer æ¶æ§‹)
    'eva02':    0.20   # è¼”åŠ©æ¨¡å‹ (å¤§å°ºå¯¸)
}
```
*   å»ºè­°çµ¦ Local CV åˆ†æ•¸è¼ƒé«˜çš„æ¨¡å‹æ›´å¤§çš„æ¬Šé‡ã€‚

---

## ğŸ“Š Configuration

ä¸»è¦åƒæ•¸ä½æ–¼ `config.py`ï¼Œå¯æ ¹æ“šç¡¬é«”èª¿æ•´ï¼š

```python
# config.py
BATCH_SIZE = 16        # ç›®æ¨™ Batch Size
CACHE_IMAGES = True    # é–‹å•Ÿ RAM Cache
USE_AMP = True         # é–‹å•Ÿæ··åˆç²¾åº¦
```

---

<div align="center">
    <p>Empowered by Advanced Agentic Coding</p>
</div>

---

## ğŸ“ˆ Performance & Results (å¯¦æˆ°æˆæ•ˆ)

æˆ‘å€‘å–®ç¨ä½¿ç”¨ **ConvNeXt V2 Large** é€²è¡Œè¨“ç·´èˆ‡æ¸¬è©¦ï¼Œåœ¨ä¸ä½¿ç”¨ä»»ä½• Ensemble çš„æƒ…æ³ä¸‹å³å–å¾—äº†é©šäººçš„æˆç¸¾ã€‚

### ğŸ… Leaderboard Ranking
*   **Rank**: **9 / 969** (Top 1%) 
*   **Score**: **0.9972872**
*   **Model**: Single ConvNeXt V2 (5-Fold CV)

<div align="center">
  <img src="assets/convnext_accuracy_chart.png" alt="Validation Accuracy" width="48%">
  <img src="assets/convnext_loss_chart.png" alt="Training Loss" width="48%">
</div>

> **Note**: è¨“ç·´æ›²ç·šé¡¯ç¤º Fold 2 èˆ‡ Fold 3 çš„ Validation Accuracy ç”šè‡³é”åˆ°äº† **100%**ï¼Œè­‰æ˜äº†æˆ‘å€‘è§£æ±ºæ–¹æ¡ˆçš„å¼·å¤§é­¯æ£’æ€§ã€‚

---

## ğŸ“š References (åƒè€ƒæ–‡ç»)

1.  **ConvNeXt V2**: [Woo, S., et al. "ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders." (2023)](https://arxiv.org/abs/2301.00808)
2.  **Swin Transformer V2**: [Liu, Z., et al. "Swin Transformer V2: Scaling Up Capacity and Resolution." (2022)](https://arxiv.org/abs/2111.09883)
3.  **EVA-02**: [Fang, Y., et al. "EVA-02: A Visual Representation for Neon Genesis." (2023)](https://arxiv.org/abs/2303.11331)
4.  **Noisy Student**: [Xie, Q., et al. "Self-training with Noisy Student improves ImageNet classification." (2020)](https://arxiv.org/abs/1911.04252)
5.  **Mean Teacher (EMA)**: [Tarvainen, A., & Valpola, H. "Mean teachers are better role models." (2017)](https://arxiv.org/abs/1703.01780)
6.  **Albumentations**: [Buslaev, A., et al. "Albumentations: Fast and Flexible Image Augmentations." (2020)](https://github.com/albumentations-team/albumentations)
7.  **AdamW (Decoupled Weight Decay)**: [Loshchilov, I., & Hutter, F. "Decoupled Weight Decay Regularization." (2017)](https://arxiv.org/abs/1711.05101)
8.  **SGDR (Cosine Annealing)**: [Loshchilov, I., & Hutter, F. "SGDR: Stochastic Gradient Descent with Warm Restarts." (2016)](https://arxiv.org/abs/1608.03983)
9.  **Gradient Clipping**: [Pascanu, R., et al. "On the difficulty of training recurrent neural networks." (2013)](https://arxiv.org/abs/1211.5063)
10. **timm (PyTorch Image Models)**: [Wightman, R. "PyTorch Image Models." (2019)](https://github.com/rwightman/pytorch-image-models)
11. **Cutout (CoarseDropout)**: [DeVries, T., & Taylor, G. W. "Improved Regularization of Convolutional Neural Networks with Cutout." (2017)](https://arxiv.org/abs/1708.04552)
